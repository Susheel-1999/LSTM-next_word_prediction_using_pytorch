{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next_word_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6BCxpxVYGKH"
      },
      "source": [
        "**Corpus to train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsYcPKpx4aPI"
      },
      "source": [
        "#read the corpus(this is a sample file, upload task specific corpus in corpus text file and proceed)\r\n",
        "corpus=open(\"corpus.txt\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "JE4Gl95pWgo3",
        "outputId": "1b1ce3ae-f408-4772-8797-2bdba79ebe37"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Next Word Prediction is also called Language Modeling. It is the task of predicting what word comes next. It is one of the fundamental tasks of NLP and has many applications. You might be using it daily when you write texts or emails without realizing it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3aWyWru49B1"
      },
      "source": [
        "#preprocess the corpus\r\n",
        "import re\r\n",
        "corpus=corpus.lower()\r\n",
        "clean_corpus=re.sub('[^a-z0-9]+',' ', corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hwPTQ7ZG4_pD",
        "outputId": "e3a15452-4815-4f4a-e154-241597de6176"
      },
      "source": [
        "clean_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'next word prediction is also called language modeling it is the task of predicting what word comes next it is one of the fundamental tasks of nlp and has many applications you might be using it daily when you write texts or emails without realizing it '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DYulqAzYxz1"
      },
      "source": [
        " **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zywUUPh75Aee",
        "outputId": "98adaf3e-af07-4242-d317-17af6f4c59e9"
      },
      "source": [
        "#required libraries\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P1LDILB5f20",
        "outputId": "e7ec9261-f829-4e8a-ddbd-05d4c63f8c73"
      },
      "source": [
        "#tokenizing the text into words\r\n",
        "tokens = word_tokenize(clean_corpus)\r\n",
        "tokens\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['next',\n",
              " 'word',\n",
              " 'prediction',\n",
              " 'is',\n",
              " 'also',\n",
              " 'called',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'it',\n",
              " 'is',\n",
              " 'the',\n",
              " 'task',\n",
              " 'of',\n",
              " 'predicting',\n",
              " 'what',\n",
              " 'word',\n",
              " 'comes',\n",
              " 'next',\n",
              " 'it',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'fundamental',\n",
              " 'tasks',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'and',\n",
              " 'has',\n",
              " 'many',\n",
              " 'applications',\n",
              " 'you',\n",
              " 'might',\n",
              " 'be',\n",
              " 'using',\n",
              " 'it',\n",
              " 'daily',\n",
              " 'when',\n",
              " 'you',\n",
              " 'write',\n",
              " 'texts',\n",
              " 'or',\n",
              " 'emails',\n",
              " 'without',\n",
              " 'realizing',\n",
              " 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvDBhC5c5j5u"
      },
      "source": [
        "#length of the sequence to train\r\n",
        "train_len = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpj6xg2T5rRq"
      },
      "source": [
        "#converting the data into required sequence\r\n",
        "text_sequences = []\r\n",
        "for i in range(train_len,len(tokens)+1):\r\n",
        "  seq = tokens[i-train_len:i]\r\n",
        "  text_sequences.append(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h8SCeRS5vwy",
        "outputId": "3ca43022-6a4a-48c1-f5c9-1c43434789b9"
      },
      "source": [
        "text_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['next', 'word', 'prediction'],\n",
              " ['word', 'prediction', 'is'],\n",
              " ['prediction', 'is', 'also'],\n",
              " ['is', 'also', 'called'],\n",
              " ['also', 'called', 'language'],\n",
              " ['called', 'language', 'modeling'],\n",
              " ['language', 'modeling', 'it'],\n",
              " ['modeling', 'it', 'is'],\n",
              " ['it', 'is', 'the'],\n",
              " ['is', 'the', 'task'],\n",
              " ['the', 'task', 'of'],\n",
              " ['task', 'of', 'predicting'],\n",
              " ['of', 'predicting', 'what'],\n",
              " ['predicting', 'what', 'word'],\n",
              " ['what', 'word', 'comes'],\n",
              " ['word', 'comes', 'next'],\n",
              " ['comes', 'next', 'it'],\n",
              " ['next', 'it', 'is'],\n",
              " ['it', 'is', 'one'],\n",
              " ['is', 'one', 'of'],\n",
              " ['one', 'of', 'the'],\n",
              " ['of', 'the', 'fundamental'],\n",
              " ['the', 'fundamental', 'tasks'],\n",
              " ['fundamental', 'tasks', 'of'],\n",
              " ['tasks', 'of', 'nlp'],\n",
              " ['of', 'nlp', 'and'],\n",
              " ['nlp', 'and', 'has'],\n",
              " ['and', 'has', 'many'],\n",
              " ['has', 'many', 'applications'],\n",
              " ['many', 'applications', 'you'],\n",
              " ['applications', 'you', 'might'],\n",
              " ['you', 'might', 'be'],\n",
              " ['might', 'be', 'using'],\n",
              " ['be', 'using', 'it'],\n",
              " ['using', 'it', 'daily'],\n",
              " ['it', 'daily', 'when'],\n",
              " ['daily', 'when', 'you'],\n",
              " ['when', 'you', 'write'],\n",
              " ['you', 'write', 'texts'],\n",
              " ['write', 'texts', 'or'],\n",
              " ['texts', 'or', 'emails'],\n",
              " ['or', 'emails', 'without'],\n",
              " ['emails', 'without', 'realizing'],\n",
              " ['without', 'realizing', 'it']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjCiH4Ss5-n5",
        "outputId": "7dd4385f-4ceb-413d-9728-a67584b27e9f"
      },
      "source": [
        "#converting the texts into integer sequence\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(text_sequences)\r\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)\r\n",
        "sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 6, 8],\n",
              " [6, 8, 2],\n",
              " [8, 2, 9],\n",
              " [2, 9, 10],\n",
              " [9, 10, 11],\n",
              " [10, 11, 12],\n",
              " [11, 12, 1],\n",
              " [12, 1, 2],\n",
              " [1, 2, 4],\n",
              " [2, 4, 13],\n",
              " [4, 13, 3],\n",
              " [13, 3, 14],\n",
              " [3, 14, 15],\n",
              " [14, 15, 6],\n",
              " [15, 6, 16],\n",
              " [6, 16, 7],\n",
              " [16, 7, 1],\n",
              " [7, 1, 2],\n",
              " [1, 2, 17],\n",
              " [2, 17, 3],\n",
              " [17, 3, 4],\n",
              " [3, 4, 18],\n",
              " [4, 18, 19],\n",
              " [18, 19, 3],\n",
              " [19, 3, 20],\n",
              " [3, 20, 21],\n",
              " [20, 21, 22],\n",
              " [21, 22, 23],\n",
              " [22, 23, 24],\n",
              " [23, 24, 5],\n",
              " [24, 5, 25],\n",
              " [5, 25, 26],\n",
              " [25, 26, 27],\n",
              " [26, 27, 1],\n",
              " [27, 1, 28],\n",
              " [1, 28, 29],\n",
              " [28, 29, 5],\n",
              " [29, 5, 30],\n",
              " [5, 30, 31],\n",
              " [30, 31, 32],\n",
              " [31, 32, 33],\n",
              " [32, 33, 34],\n",
              " [33, 34, 35],\n",
              " [34, 35, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6nq0UxoHCb5"
      },
      "source": [
        "sequences=np.asarray(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr8-K-iPIkEC",
        "outputId": "39a655e9-dd85-4ed1-d40f-112905fb715b"
      },
      "source": [
        "#vocabulary size\r\n",
        "vocabulary_size = len(tokenizer.word_counts)+1\r\n",
        "vocabulary_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfNmEO-_IEHh"
      },
      "source": [
        "#trainX\r\n",
        "train_inputs=sequences[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXDhSpKUILHG",
        "outputId": "dddbfc69-b938-40a7-a9f5-93170ade0408"
      },
      "source": [
        "train_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  6],\n",
              "       [ 6,  8],\n",
              "       [ 8,  2],\n",
              "       [ 2,  9],\n",
              "       [ 9, 10],\n",
              "       [10, 11],\n",
              "       [11, 12],\n",
              "       [12,  1],\n",
              "       [ 1,  2],\n",
              "       [ 2,  4],\n",
              "       [ 4, 13],\n",
              "       [13,  3],\n",
              "       [ 3, 14],\n",
              "       [14, 15],\n",
              "       [15,  6],\n",
              "       [ 6, 16],\n",
              "       [16,  7],\n",
              "       [ 7,  1],\n",
              "       [ 1,  2],\n",
              "       [ 2, 17],\n",
              "       [17,  3],\n",
              "       [ 3,  4],\n",
              "       [ 4, 18],\n",
              "       [18, 19],\n",
              "       [19,  3],\n",
              "       [ 3, 20],\n",
              "       [20, 21],\n",
              "       [21, 22],\n",
              "       [22, 23],\n",
              "       [23, 24],\n",
              "       [24,  5],\n",
              "       [ 5, 25],\n",
              "       [25, 26],\n",
              "       [26, 27],\n",
              "       [27,  1],\n",
              "       [ 1, 28],\n",
              "       [28, 29],\n",
              "       [29,  5],\n",
              "       [ 5, 30],\n",
              "       [30, 31],\n",
              "       [31, 32],\n",
              "       [32, 33],\n",
              "       [33, 34],\n",
              "       [34, 35]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARHKHlWtIm5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf9dc37-cfdb-472b-89bb-8fdb0c961ff5"
      },
      "source": [
        "#input sequence length \r\n",
        "seq_length=train_inputs.shape[1]\r\n",
        "seq_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O--gWQUxINzs"
      },
      "source": [
        "#trainY\r\n",
        "train_targets=sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN5KSn9RIRKL",
        "outputId": "a78158fd-47ba-49f1-e7c9-a17a189fa4af"
      },
      "source": [
        "train_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  2,  9, 10, 11, 12,  1,  2,  4, 13,  3, 14, 15,  6, 16,  7,  1,\n",
              "        2, 17,  3,  4, 18, 19,  3, 20, 21, 22, 23, 24,  5, 25, 26, 27,  1,\n",
              "       28, 29,  5, 30, 31, 32, 33, 34, 35,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu-jsQuIIV38"
      },
      "source": [
        "#one hot encoding\r\n",
        "train_targets = to_categorical(train_targets, num_classes=vocabulary_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8_Eq-F5Iaeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18a0221-5fe5-476b-c46a-dd2924bef2e7"
      },
      "source": [
        "train_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arECrPWAbbCl"
      },
      "source": [
        "**Let's build the model!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAOhMFUdIzRV"
      },
      "source": [
        "#required libraries\r\n",
        "import torch\r\n",
        "from torch.optim import Adam\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cixhhmGXIzX-"
      },
      "source": [
        "#lstm model\r\n",
        "class lstm(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\r\n",
        "        super().__init__()\r\n",
        "        #simple lookup table that stores embeddings of a fixed dictionary and size.\r\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\r\n",
        "        \r\n",
        "        #lstm \r\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=2, bidirectional=False)\r\n",
        "        \r\n",
        "        #fully connected layer\r\n",
        "        self.linear = nn.Linear(hidden_size*seq_length,vocab_size)\r\n",
        "    \r\n",
        "    def forward(self, input_word):\r\n",
        "        #input sequence to embeddings\r\n",
        "        embedded = self.embed(input_word)\r\n",
        "        \r\n",
        "        #passing the embedding to lstm model\r\n",
        "        output, hidden = self.lstm(embedded)\r\n",
        "        \r\n",
        "        #reshaping\r\n",
        "        output=output.view(output.size(0), -1)\r\n",
        "        \r\n",
        "        #fully connected layer\r\n",
        "        output = self.linear(output)\r\n",
        "        return output,hidden\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIrit6u4Izbc"
      },
      "source": [
        "model=lstm(vocab_size=vocabulary_size,embed_size=128, hidden_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsk3-AHhJDUr",
        "outputId": "5f3af3a2-4da9-4188-de19-3a6b35f0efd1"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm(\n",
              "  (embed): Embedding(36, 128)\n",
              "  (lstm): LSTM(128, 256, num_layers=2)\n",
              "  (linear): Linear(in_features=512, out_features=36, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hRysclwJEhK"
      },
      "source": [
        "#Adam optimizer\r\n",
        "optimizer= Adam(model.parameters(), lr=0.07)\r\n",
        "\r\n",
        "#loss\r\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kg9Xel5JGRJ"
      },
      "source": [
        "#training the model\r\n",
        "def train(epoch):\r\n",
        "    #set the model to train\r\n",
        "    model.train()\r\n",
        "    tr_loss=0    \r\n",
        "    \r\n",
        "    #clearing the Gradients \r\n",
        "    optimizer.zero_grad()\r\n",
        "    \r\n",
        "    #predict the output\r\n",
        "    y_pred, (state_h, state_c) = model(torch.from_numpy(train_inputs))\r\n",
        "    \r\n",
        "    #compute the loss\r\n",
        "    loss=criterion(y_pred,torch.from_numpy(train_targets))\r\n",
        "    losses.append(loss)\r\n",
        "    \r\n",
        "    #backpropagate\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    #update the parameters\r\n",
        "    optimizer.step()\r\n",
        "    tr_loss = loss.item()\r\n",
        "\r\n",
        "    print(\"Epoch : \",epoch,\"loss : \",loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ozm9y0uJbVN",
        "outputId": "ef6aab79-52fa-4a21-c209-8bf01767e3f9"
      },
      "source": [
        "#number of epoch\r\n",
        "no_epoch=50\r\n",
        "losses=[]\r\n",
        "for epoch in range(1,no_epoch+1):\r\n",
        "    train(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  1 loss :  tensor(0.6966, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  2 loss :  tensor(0.4375, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  3 loss :  tensor(2.0284, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  4 loss :  tensor(1.4217, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  5 loss :  tensor(0.6946, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  6 loss :  tensor(0.1620, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  7 loss :  tensor(0.1574, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  8 loss :  tensor(0.1704, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  9 loss :  tensor(0.1815, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  10 loss :  tensor(0.1772, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  11 loss :  tensor(0.1703, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  12 loss :  tensor(0.1565, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  13 loss :  tensor(0.1505, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  14 loss :  tensor(0.1485, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  15 loss :  tensor(0.1362, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  16 loss :  tensor(0.1347, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  17 loss :  tensor(0.1249, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  18 loss :  tensor(0.1152, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  19 loss :  tensor(0.1256, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  20 loss :  tensor(0.1075, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  21 loss :  tensor(0.1169, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  22 loss :  tensor(0.1116, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  23 loss :  tensor(0.1024, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  24 loss :  tensor(0.0949, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  25 loss :  tensor(0.0914, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  26 loss :  tensor(0.0872, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  27 loss :  tensor(0.0827, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  28 loss :  tensor(0.0748, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  29 loss :  tensor(0.0764, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  30 loss :  tensor(0.0712, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  31 loss :  tensor(0.0707, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  32 loss :  tensor(0.0679, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  33 loss :  tensor(0.0661, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  34 loss :  tensor(0.0615, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  35 loss :  tensor(0.0581, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  36 loss :  tensor(0.0536, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  37 loss :  tensor(0.0504, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  38 loss :  tensor(0.0520, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  39 loss :  tensor(0.0463, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  40 loss :  tensor(0.0445, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  41 loss :  tensor(0.0435, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  42 loss :  tensor(0.0416, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  43 loss :  tensor(0.0390, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  44 loss :  tensor(0.0358, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  45 loss :  tensor(0.0340, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  46 loss :  tensor(0.0339, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  47 loss :  tensor(0.0307, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  48 loss :  tensor(0.0298, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  49 loss :  tensor(0.0283, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Epoch :  50 loss :  tensor(0.0268, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "l64AXxzzdYd9",
        "outputId": "bffd5c39-7f93-4780-9071-4b6eb2810f3a"
      },
      "source": [
        "#plotting the loss, loss is decreasing for each epoch\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(losses, label='Training loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpIMkQsQdmnM"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmBgWH0aKdmV"
      },
      "source": [
        "def predict_next_word(text):\r\n",
        "    #set the model to evaluation\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    #preprocess\r\n",
        "    text = text.lower().strip()\r\n",
        "    \r\n",
        "    #converting the text to word tokens\r\n",
        "    input_tokens = word_tokenize(text)\r\n",
        "    \r\n",
        "    #converting the tokens to integer sequence\r\n",
        "    sequences = tokenizer.texts_to_sequences([input_tokens])\r\n",
        "    \r\n",
        "    #converting to array\r\n",
        "    sequences=np.asarray(sequences)\r\n",
        "    with torch.no_grad():\r\n",
        "        #converting to tensor\r\n",
        "        sequences=torch.from_numpy(sequences)\r\n",
        "        #predicting the output\r\n",
        "        predict,(hidden,cell)=model(sequences)\r\n",
        "    \r\n",
        "    #applying the softmax layer\r\n",
        "    softmax = torch.exp(predict)\r\n",
        "    prob = list(softmax.numpy())\r\n",
        "    \r\n",
        "    #index of the predict word\r\n",
        "    predictions = np.argmax(prob)\r\n",
        "\r\n",
        "    #converting the sequence back to word\r\n",
        "    next_word=tokenizer.sequences_to_texts([[predictions]])\r\n",
        "    return next_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw5HAQI1fTpS"
      },
      "source": [
        "*Example-1*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_owlCiyoeVw_"
      },
      "source": [
        "#we trained our model with sequence length of 2\r\n",
        "input_text=\"next word\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tzpeDk5exQ6",
        "outputId": "c97fd5cb-7b39-4b90-e646-e36c42c94603"
      },
      "source": [
        "print(\"Possible next word will be:\")\r\n",
        "predict_next_word(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible next word will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prediction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDvZaEfSfW1u"
      },
      "source": [
        "*Example-2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b46SBQufSJ2"
      },
      "source": [
        "#we trained our model with sequence length of 2\r\n",
        "input_text=\"NLP language\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QwGqdILfSJ5",
        "outputId": "8aa8d197-e967-461f-a46d-c112990170bb"
      },
      "source": [
        "print(\"Possible next word will be:\")\r\n",
        "predict_next_word(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible next word will be:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['modeling']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS23nvl-hfzK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
